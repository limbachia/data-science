{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web-Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First install scrapy. Check installation a guid here https://docs.scrapy.org/en/latest/intro/install.html#intro-install\n",
    "\n",
    "In this tutorial, we will be scraping https://fundrazr.com/find. Partticularly, the campaigns mentioned under Health & Illness (https://fundrazr.com/find?category=Health).\n",
    "\n",
    "Scarpy usage with example can be found at https://github.com/mGalarnyk/Python_Tutorials/tree/master/Scrapy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at the webpage that lists all campaigns for Health & Illness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src=\"https://fundrazr.com/find?category=Health\" width=\"500\" height=\"400\"></iframe>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<iframe src=\"https://fundrazr.com/find?category=Health\" width=\"500\" height=\"400\"></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is only the first page. There are several pages, each with 12 campaigns. \n",
    "\n",
    "For this exercise, we will scrap information only from the first page (i.e., 12 campaigns). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "\n",
    "# Import TextResponse module from scrapy\n",
    "from scrapy.http import TextResponse\n",
    "\n",
    "# Import the request library\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TextResponse is a convenient module that allows us to use xpath feature of *scrapy* without having to run the scrapy shell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Campaigns listed on the first page\n",
      "//fundrazr.com/americangut\n",
      "//fundrazr.com/IndonesiaCOVID\n",
      "//fundrazr.com/britishgut\n",
      "//fundrazr.com/f13EF1\n",
      "//fundrazr.com/ViewHealthcareHeroes\n",
      "//fundrazr.com/helpleewana\n",
      "//fundrazr.com/RHK8_Snacks_2019\n",
      "//fundrazr.com/71YCU4\n",
      "//fundrazr.com/AlinkerwalkingbikeforHopesmom\n",
      "//fundrazr.com/9OsT5\n",
      "//fundrazr.com/31XUGd\n",
      "//fundrazr.com/31WUvb\n"
     ]
    }
   ],
   "source": [
    "# Send request to access the first page of Health & Illness campaign.\n",
    "\n",
    "res = requests.get(\"https://fundrazr.com/find?category=Health\")\n",
    "response = TextResponse(res.url,body=res.text,encoding='utf-8')\n",
    "\n",
    "hrefs = response.xpath(\"//h2[contains(@class, 'title headline-font')]/a[contains(@class, 'campaign-link')]//@href\").extract()\n",
    "print('Campaigns listed on the first page')\n",
    "print('\\n'.join(hrefs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above list are partial urls for each of the 12 campaigns listed on the first page.\n",
    "\n",
    "The code below creates complete url by prepending the partial urls with 'https.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://fundrazr.com/americangut\n",
      "https://fundrazr.com/IndonesiaCOVID\n",
      "https://fundrazr.com/britishgut\n",
      "https://fundrazr.com/f13EF1\n",
      "https://fundrazr.com/ViewHealthcareHeroes\n",
      "https://fundrazr.com/helpleewana\n",
      "https://fundrazr.com/RHK8_Snacks_2019\n",
      "https://fundrazr.com/71YCU4\n",
      "https://fundrazr.com/AlinkerwalkingbikeforHopesmom\n",
      "https://fundrazr.com/9OsT5\n",
      "https://fundrazr.com/31XUGd\n",
      "https://fundrazr.com/31WUvb\n"
     ]
    }
   ],
   "source": [
    "campaign_urls = []\n",
    "for href in hrefs:\n",
    "    campaign_urls.append(\"https:\" + href)\n",
    "    \n",
    "print('\\n'.join(campaign_urls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have urls for every campaign, we can launch scrapy shell (or use TextResponse) on every campaign to extract relevant information.\n",
    "\n",
    "Let's extract the following information from each of the 12 campaigns:\n",
    "\n",
    "1. Title\n",
    "2. Amount of money raised\n",
    "3. Number of contributors\n",
    "4. Length of time the campaign is running for\n",
    "\n",
    "Following is a dictionary containing strings that serve as inputs to xpath. Format of the strings define what information is to be scraped. This step is the heart of this exercise. Make sure you understand the string format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "xpaths = {\n",
    "    'title':\"//title/text()\",\n",
    "    'currency':\"//span[contains(@class,'currency-symbol')]/text()\",\n",
    "    'moneyRaised':\"//span[contains(@class,'amount-raised')]/descendant::text()\",\n",
    "    \"contributors\":\"//span[contains(@class,'donation-count stat')]/descendant::text()\",\n",
    "    \"duration\":\"//span[contains(@class,'stats-label lowercase')]//span[contains(@class,'stat')]/text()\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import re\n",
    "\n",
    "data = defaultdict(list)\n",
    "\n",
    "for url in campaign_urls:\n",
    "    res = requests.get(url)\n",
    "    response = TextResponse(res.url,body=res.text,encoding='utf-8')\n",
    "    for xpath in xpaths:\n",
    "        if xpath in ['title','moneyRaised','contributors','currency']:\n",
    "            data[xpath].append(response.xpath(xpaths[xpath]).extract()[0])\n",
    "        elif xpath == 'duration':\n",
    "            d = response.xpath(xpaths[xpath]).extract()\n",
    "            d = ' '.join([val for val in [re.sub('\\n|\\t','',s) for s in d] if val != ''])\n",
    "            data[xpath].append(d)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the scrapped data in now stored in the 'data' dictionary.\n",
    "\n",
    "Convert it to a dataframe to make it see the data in a tabular form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>currency</th>\n",
       "      <th>moneyRaised</th>\n",
       "      <th>contributors</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>American Gut by American Gut Project (UC San D...</td>\n",
       "      <td>$</td>\n",
       "      <td>1,943,404</td>\n",
       "      <td>12799</td>\n",
       "      <td>7 Years running</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TOPENG SEHAT: Providing Respirator Masks for I...</td>\n",
       "      <td>$</td>\n",
       "      <td>8,219</td>\n",
       "      <td>58</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>British Gut by American Gut Project (UC San Di...</td>\n",
       "      <td>£</td>\n",
       "      <td>741,115</td>\n",
       "      <td>7128</td>\n",
       "      <td>5 Years running</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Help Us Make Ireland's Dream a Reality! by Ire...</td>\n",
       "      <td>$</td>\n",
       "      <td>1,952</td>\n",
       "      <td>28</td>\n",
       "      <td>4 Years running</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rescue Detroit Restaurants - Feed Healthcare W...</td>\n",
       "      <td>$</td>\n",
       "      <td>2,625</td>\n",
       "      <td>31</td>\n",
       "      <td>25 Days running</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Help Leewana heal -- get her back in action! b...</td>\n",
       "      <td>$</td>\n",
       "      <td>4,801</td>\n",
       "      <td>104</td>\n",
       "      <td>0 days left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Healthy Snack Workshop by Raleigh Hills K8 6th...</td>\n",
       "      <td>$</td>\n",
       "      <td>1,020</td>\n",
       "      <td>16</td>\n",
       "      <td>0 days left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Please help me #keepmoving #outdoors with an #...</td>\n",
       "      <td>$</td>\n",
       "      <td>2,850</td>\n",
       "      <td>39</td>\n",
       "      <td>0 days left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Help me stay #unstoppable with an Alinker walk...</td>\n",
       "      <td>$</td>\n",
       "      <td>2,800</td>\n",
       "      <td>21</td>\n",
       "      <td>0 days left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Operation Walk USA by Operation Walk USA</td>\n",
       "      <td>$</td>\n",
       "      <td>17,275</td>\n",
       "      <td>30</td>\n",
       "      <td>7 Years running</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Transforming lives through the gift of vision!...</td>\n",
       "      <td>$</td>\n",
       "      <td>560</td>\n",
       "      <td>3</td>\n",
       "      <td>0 days left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>YAY WE DID IT!!! Now please share the other ca...</td>\n",
       "      <td>$</td>\n",
       "      <td>2,850</td>\n",
       "      <td>27</td>\n",
       "      <td>0 days left</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title currency moneyRaised  \\\n",
       "0   American Gut by American Gut Project (UC San D...        $   1,943,404   \n",
       "1   TOPENG SEHAT: Providing Respirator Masks for I...        $       8,219   \n",
       "2   British Gut by American Gut Project (UC San Di...        £     741,115   \n",
       "3   Help Us Make Ireland's Dream a Reality! by Ire...        $       1,952   \n",
       "4   Rescue Detroit Restaurants - Feed Healthcare W...        $       2,625   \n",
       "5   Help Leewana heal -- get her back in action! b...        $       4,801   \n",
       "6   Healthy Snack Workshop by Raleigh Hills K8 6th...        $       1,020   \n",
       "7   Please help me #keepmoving #outdoors with an #...        $       2,850   \n",
       "8   Help me stay #unstoppable with an Alinker walk...        $       2,800   \n",
       "9            Operation Walk USA by Operation Walk USA        $      17,275   \n",
       "10  Transforming lives through the gift of vision!...        $         560   \n",
       "11  YAY WE DID IT!!! Now please share the other ca...        $       2,850   \n",
       "\n",
       "   contributors         duration  \n",
       "0         12799  7 Years running  \n",
       "1            58                   \n",
       "2          7128  5 Years running  \n",
       "3            28  4 Years running  \n",
       "4            31  25 Days running  \n",
       "5           104      0 days left  \n",
       "6            16      0 days left  \n",
       "7            39      0 days left  \n",
       "8            21      0 days left  \n",
       "9            30  7 Years running  \n",
       "10            3      0 days left  \n",
       "11           27      0 days left  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If need to scrap data from multiple pages, repeat the above process on each page. You can start with the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_urls = [\"https://fundrazr.com/find?category=Health\"]\n",
    "\n",
    "npages = 2\n",
    "\n",
    "# This mimics getting the pages using the next button.\n",
    "for i in range(2, npages+2):\n",
    "    start_urls.append(\"https://fundrazr.com/find?category=Health&page=\"+str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://fundrazr.com/find?category=Health',\n",
       " 'https://fundrazr.com/find?category=Health&page=2',\n",
       " 'https://fundrazr.com/find?category=Health&page=3']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
